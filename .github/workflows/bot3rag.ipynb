{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyP1W0OhBbYyyH71yEprTZK3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"source":["from IPython import get_ipython\n","from IPython.display import display\n","# %%\n","# Install required libraries\n","!pip install -q langchain langchain-community faiss-cpu sentence-transformers huggingface_hub datasets\n","\n","# Import modules\n","from langchain.document_loaders import WebBaseLoader\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain.embeddings import HuggingFaceEmbeddings\n","from langchain.vectorstores import FAISS\n","from langchain.chains import RetrievalQA\n","from langchain.llms import HuggingFaceHub\n","\n","# 1. Load Documents (Using AI Wikipedia page)\n","loader = WebBaseLoader([\"https://en.wikipedia.org/wiki/Artificial_intelligence\"])\n","docs = loader.load()\n","\n","# 2. Split Documents\n","text_splitter = RecursiveCharacterTextSplitter(\n","    chunk_size=1000,\n","    chunk_overlap=200\n",")\n","splits = text_splitter.split_documents(docs)\n","\n","# 3. Create Embeddings\n","embedding_model = HuggingFaceEmbeddings(\n","    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",")\n","\n","# 4. Store in VectorDB\n","vectorstore = FAISS.from_documents(splits, embedding_model)\n","\n","# 5. Initialize Free LLM (Using Hugging Face Free Inference API)\n","import os\n","# Set the Hugging Face API token as an environment variable\n","os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\"  # Replace \"your_hf_token\" with your actual Hugging Face token from https://huggingface.co/settings/tokens\n","\n","llm = HuggingFaceHub(\n","    repo_id=\"google/flan-t5-xxl\",\n","    model_kwargs={\"temperature\":0.5, \"max_length\":512}\n",")\n","\n","# 6. Create RAG Chain\n","qa_chain = RetrievalQA.from_chain_type(\n","    llm,\n","    retriever=vectorstore.as_retriever(),\n","    return_source_documents=True\n",")\n","\n","# 7. Query the System\n","query = \"What are the main applications of AI?\"\n","result = qa_chain({\"query\": query})\n","\n","print(\"Answer:\", result[\"result\"])\n","print(\"\\nSources:\")\n","for doc in result[\"source_documents\"][:3]:\n","    print(f\"- {doc.metadata['source']}: {doc.page_content[:150]}...\")"],"cell_type":"code","metadata":{"id":"SZiwrcEsKNih"},"execution_count":null,"outputs":[]},{"source":["!pip install gradio"],"cell_type":"code","metadata":{"id":"HEQmOsYMQP9i"},"execution_count":null,"outputs":[]},{"source":["from IPython import get_ipython\n","from IPython.display import display\n","# %%\n","# Install required libraries\n","!pip install -q langchain langchain-community faiss-cpu sentence-transformers huggingface_hub datasets gradio\n","\n","# Import modules\n","from langchain.document_loaders import WebBaseLoader\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain.embeddings import HuggingFaceEmbeddings\n","from langchain.vectorstores import FAISS\n","from langchain.chains import RetrievalQA\n","from langchain.llms import HuggingFaceHub\n","import gradio as gr\n","\n","# 1. Load Documents (Using AI Wikipedia page)\n","loader = WebBaseLoader([\"https://en.wikipedia.org/wiki/Artificial_intelligence\"])\n","docs = loader.load()\n","\n","# 2. Split Documents\n","text_splitter = RecursiveCharacterTextSplitter(\n","    chunk_size=1000,\n","    chunk_overlap=200\n",")\n","splits = text_splitter.split_documents(docs)\n","\n","# 3. Create Embeddings\n","embedding_model = HuggingFaceEmbeddings(\n","    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",")\n","\n","# 4. Store in VectorDB\n","vectorstore = FAISS.from_documents(splits, embedding_model)\n","\n","# 5. Initialize Free LLM (Using Hugging Face Free Inference API)\n","import os\n","# Set the Hugging Face API token as an environment variable\n","# Make sure to replace \"YOUR_ACTUAL_HF_TOKEN\" with your actual Hugging Face token\n","os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\"\n","\n","# Using a smaller model to avoid size limits\n","# Try 'google/flan-t5-large' or 'google/flan-t5-base'\n","llm = HuggingFaceHub(\n","    repo_id=\"google/flan-t5-large\",  # Switched to a smaller model\n","    model_kwargs={\"temperature\":0.5, \"max_length\":512}\n",")\n","\n","# 6. Create RAG Chain\n","qa_chain = RetrievalQA.from_chain_type(\n","    llm,\n","    retriever=vectorstore.as_retriever(),\n","    return_source_documents=True\n",")\n","\n","# Function to get answer from the RAG chain\n","def get_answer(query):\n","    result = qa_chain({\"query\": query})\n","    answer = result[\"result\"]\n","    sources = \"\\nSources:\\n\"\n","    for doc in result[\"source_documents\"][:3]:\n","        sources += f\"- {doc.metadata['source']}: {doc.page_content[:150]}...\\n\"\n","    return answer + sources\n","\n","# Create the Gradio interface\n","iface = gr.Interface(\n","    fn=get_answer,\n","    inputs=gr.Textbox(lines=2, placeholder=\"Enter your question here...\"),\n","    outputs=\"text\",\n","    title=\"AI Wikipedia RAG\",\n","    description=\"Ask questions about Artificial Intelligence from Wikipedia.\",\n",")\n","\n","# Launch the interface\n","iface.launch()"],"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":646},"id":"GLF6d0bTNvEw","executionInfo":{"status":"ok","timestamp":1737805110168,"user_tz":0,"elapsed":11472,"user":{"displayName":"Lakho GM","userId":"10558160477052294353"}},"outputId":"f7116e9c-4b0c-4380-966c-064270cf1105"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n","\n","Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","* Running on public URL: https://3af2de8ede8f7de769.gradio.live\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://3af2de8ede8f7de769.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":4}]},{"source":["from IPython import get_ipython\n","from IPython.display import display\n","# %%\n","# Install required libraries\n","!pip install -q langchain langchain-community faiss-cpu sentence-transformers huggingface_hub datasets\n","\n","# Import modules\n","from langchain.document_loaders import WebBaseLoader\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain.embeddings import HuggingFaceEmbeddings\n","from langchain.vectorstores import FAISS\n","from langchain.chains import RetrievalQA\n","from langchain.llms import HuggingFaceHub\n","\n","# 1. Load Documents (Using AI Wikipedia page)\n","loader = WebBaseLoader([\"https://en.wikipedia.org/wiki/Artificial_intelligence\"])\n","docs = loader.load()\n","\n","# 2. Split Documents\n","text_splitter = RecursiveCharacterTextSplitter(\n","    chunk_size=1000,\n","    chunk_overlap=200\n",")\n","splits = text_splitter.split_documents(docs)\n","\n","# 3. Create Embeddings\n","embedding_model = HuggingFaceEmbeddings(\n","    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",")\n","\n","# 4. Store in VectorDB\n","vectorstore = FAISS.from_documents(splits, embedding_model)\n","\n","# 5. Initialize Free LLM (Using Hugging Face Free Inference API)\n","import os\n","# Set the Hugging Face API token as an environment variable\n","# Make sure to replace \"YOUR_ACTUAL_HF_TOKEN\" with your actual Hugging Face token\n","os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\"\n","\n","# Using a smaller model to avoid size limits\n","# Try 'google/flan-t5-large' or 'google/flan-t5-base'\n","llm = HuggingFaceHub(\n","    repo_id=\"google/flan-t5-large\",  # Switched to a smaller model\n","    model_kwargs={\"temperature\":0.5, \"max_length\":512}\n",")\n","\n","# 6. Create RAG Chain\n","qa_chain = RetrievalQA.from_chain_type(\n","    llm,\n","    retriever=vectorstore.as_retriever(),\n","    return_source_documents=True\n",")\n","\n","# 7. Query the System\n","query = \"What are the main applications of AI?\"\n","result = qa_chain({\"query\": query})\n","\n","print(\"Answer:\", result[\"result\"])\n","print(\"\\nSources:\")\n","for doc in result[\"source_documents\"][:3]:\n","    print(f\"- {doc.metadata['source']}: {doc.page_content[:150]}...\")"],"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ylHP9F__MH_m","executionInfo":{"status":"ok","timestamp":1737804136137,"user_tz":0,"elapsed":9063,"user":{"displayName":"Lakho GM","userId":"10558160477052294353"}},"outputId":"7a45a037-8ef5-4eb9-94d6-c449d01d7165"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Answer: advanced web search engines\n","\n","Sources:\n","- https://en.wikipedia.org/wiki/Artificial_intelligence: High-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netfli...\n","- https://en.wikipedia.org/wiki/Artificial_intelligence: Various subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include re...\n","- https://en.wikipedia.org/wiki/Artificial_intelligence: Applications\n","Main article: Applications of artificial intelligenceAI and machine learning technology is used in most of the essential applications of ...\n"]}]},{"source":[],"cell_type":"code","metadata":{"id":"JkHDmFcXHE8K"},"execution_count":null,"outputs":[]}]}